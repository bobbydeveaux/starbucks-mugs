GeneratedAt: "2026-02-26T11:29:35Z"
Plan: fileguard-plan
Sprints:
- Features:
  - FeatureID: fileguard-feat-pii-detector
    FeatureTitle: PII Detection Engine
    Tasks:
    - AcceptanceCriteria:
      - All five UK pattern types match valid examples and reject invalid ones
      - Custom patterns from a JSON config file are loaded and merged at startup without
        restart
      - All patterns are pre-compiled on load; no re-compilation occurs at scan time
      AgentType: backend-engineer
      Dependencies: []
      Description: Build the built-in UK PII pattern library covering NI numbers,
        NHS numbers, email, phone, and postcode. Support loading additional custom
        patterns from a JSON config file at startup, merging them with the built-in
        set. Pre-compile all regex patterns for performance.
      EstimatedEffort: M
      Files:
      - fileguard/core/patterns/uk_patterns.py
      ID: task-fileguard-feat-pii-detector-1
      Title: Implement UK regex pattern library with JSON config loading
    - AcceptanceCriteria:
      - Findings include category, severity level, matched value, and byte offset
        for every match
      - PIIDetector integrates with ScanContext and appends findings to the pipeline
        result
      - Unit tests cover multi-pattern documents, overlapping matches, and empty input
      AgentType: backend-engineer
      Dependencies:
      - task-fileguard-feat-pii-detector-1
      Description: Implement the PIIDetector class that runs the compiled pattern
        set against extracted text and returns structured findings with category,
        severity, and byte offset. Integrate with ScanContext so findings are attached
        to the pipeline result. Depend on the pattern library from task 1.
      EstimatedEffort: M
      Files:
      - fileguard/core/pii_detector.py
      ID: task-fileguard-feat-pii-detector-2
      Title: Implement PIIDetector core engine
    - AcceptanceCriteria:
      - Both adapters implement the same interface and are selectable via tenant config
      - Cloud findings are normalised to the same category/severity/byte-offset schema
        as local findings
      - A cloud backend failure triggers fail-secure behaviour and surfaces an error
        code rather than returning partial results silently
      AgentType: backend-engineer
      Dependencies:
      - task-fileguard-feat-pii-detector-2
      Description: Implement configurable cloud adapter backends for Google DLP and
        AWS Macie that conform to a common adapter interface. Adapters are selected
        via tenant config at runtime and supplement or replace local regex scanning.
        Include error handling so a cloud backend failure falls back securely.
      EstimatedEffort: L
      Files:
      - fileguard/core/adapters/dlp_adapter.py
      - fileguard/core/adapters/macie_adapter.py
      ID: task-fileguard-feat-pii-detector-3
      Title: Implement Google DLP and AWS Macie cloud adapter backends
  - FeatureID: fileguard-feat-siem-forwarding
    FeatureTitle: SIEM Event Forwarding
    Tasks:
    - AcceptanceCriteria:
      - ScanEvent records are forwarded asynchronously to Splunk HEC endpoint without
        blocking scan response
      - ScanEvent records are forwarded asynchronously to RiverSafe WatchTower REST
        API without blocking scan response
      - Prometheus counter `siem_delivery_errors_total` is incremented on any failed
        delivery attempt
      - Unit tests cover successful delivery, network failure retry, and error counter
        increment for both destinations
      AgentType: backend-engineer
      Dependencies: []
      Description: Implement SIEMService in fileguard/services/siem.py with async
        forwarding of ScanEvent records to both Splunk HEC and RiverSafe WatchTower
        REST API. The service must be fully decoupled from the scan critical path
        (fire-and-forget via asyncio or Celery task), include retry logic, and increment
        a Prometheus counter on delivery errors.
      EstimatedEffort: M
      Files:
      - fileguard/services/siem.py
      - fileguard/tests/test_siem.py
      ID: task-fileguard-feat-siem-forwarding-1
      Title: Implement async SIEM forwarding service
    - AcceptanceCriteria:
      - Alert rule `SIEMHighDeliveryErrorRate` fires when error rate > 0.5% over a
        5-minute window
      - Alert configuration is valid and loads without errors in Prometheus
      AgentType: devops-engineer
      Dependencies:
      - task-fileguard-feat-siem-forwarding-1
      Description: Add a Prometheus alerting rule that fires when the SIEM delivery
        error rate exceeds 0.5% over a sliding window. Wire the rule into the existing
        alert configuration and validate it against the counter emitted by the SIEM
        service.
      EstimatedEffort: S
      Files:
      - deploy/prometheus/alerts/siem.yaml
      ID: task-fileguard-feat-siem-forwarding-2
      Title: Add Prometheus alert rule for SIEM failure rate
  - FeatureID: fileguard-feat-compliance-reports
    FeatureTitle: Scheduled Compliance Report Generation
    Tasks:
    - AcceptanceCriteria:
      - ReportSchema Pydantic models validate report payloads including file_count,
        verdict_breakdown dict, and pii_hits_by_category dict
      - Celery beat task runs on configurable daily/weekly cadence and writes a compliance_report
        row with status=completed
      - Generated JSON report contains correct aggregated metrics for the report period
        drawn from scan_event records
      - PDF report is produced without error and stored to the configured output location
      AgentType: backend-engineer
      Dependencies: []
      Description: Define Pydantic schemas for compliance report data structures and
        implement the reports service with Celery tasks for configurable daily/weekly
        scheduling. The service queries scan_event and compliance_report tables to
        aggregate file counts, verdict breakdowns, and PII hit counts by category,
        then persists both PDF and JSON output.
      EstimatedEffort: L
      Files:
      - fileguard/schemas/report.py
      - fileguard/services/reports.py
      ID: task-fileguard-feat-compliance-reports-1
      Title: Implement compliance report schema and Celery generation service
    - AcceptanceCriteria:
      - GET /v1/reports returns 200 with paginated list of compliance_report metadata
        records for the authenticated tenant
      - 'GET /v1/reports/{id}/download returns the PDF file with Content-Type: application/pdf
        or JSON body depending on Accept header'
      - GET /v1/reports/{id}/download returns 404 when the report ID does not exist
        or belongs to another tenant
      - Both endpoints are covered by integration tests that exercise the happy path
        and error cases
      AgentType: backend-engineer
      Dependencies:
      - task-fileguard-feat-compliance-reports-1
      Description: Implement the GET /v1/reports list endpoint and GET /v1/reports/{id}/download
        endpoint in the FastAPI handler. The list endpoint returns paginated report
        metadata; the download endpoint streams the stored PDF or returns JSON based
        on Accept header, with appropriate 404 handling for unknown report IDs.
      EstimatedEffort: M
      Files:
      - fileguard/api/handlers/reports.py
      ID: task-fileguard-feat-compliance-reports-2
      Title: Implement report retrieval API handlers
  Sprint: 3
- Features:
  - FeatureID: fileguard-feat-redaction
    FeatureTitle: PII Redaction Engine
    Tasks:
    - AcceptanceCriteria:
      - RedactionEngine.redact() accepts ScanContext with PIIDetector findings and
        returns redacted content string
      - Overlapping or adjacent spans are merged before substitution to avoid double-redaction
        or index drift
      - Redacted output preserves non-PII content exactly (character-level diff excluding
        replaced spans)
      - Unit tests cover zero findings, single span, multiple non-overlapping spans,
        and overlapping spans
      AgentType: backend-engineer
      Dependencies: []
      Description: Implement the RedactionEngine class in fileguard/core/redaction.py.
        Accept PIIDetector findings (span offsets and labels), replace each matched
        span with a [REDACTED] token using offset-safe in-place substitution, and
        reconstruct the output document preserving original format and structure.
      EstimatedEffort: M
      Files:
      - fileguard/core/redaction.py
      - tests/unit/test_redaction.py
      ID: task-fileguard-feat-redaction-1
      Title: Implement RedactionEngine span replacement and file reconstruction
    - AcceptanceCriteria:
      - Signed URL is generated with configurable TTL and points to the redacted file
        in object storage
      - Signed URL is only produced when the caller explicitly requests redaction
        in the scan request
      - Integration test confirms URL resolves to content where all PII spans are
        replaced with [REDACTED]
      AgentType: backend-engineer
      Dependencies:
      - task-fileguard-feat-redaction-1
      Description: Extend RedactionEngine (or a thin service wrapper) to write the
        redacted content to object storage and return a time-limited signed URL. Wire
        this into the scan pipeline so callers receive the URL in the ScanContext
        response payload when redaction is requested.
      EstimatedEffort: S
      Files:
      - fileguard/core/redaction.py
      - fileguard/services/storage.py
      ID: task-fileguard-feat-redaction-2
      Title: Expose redacted file via signed URL
  - FeatureID: fileguard-feat-disposition
    FeatureTitle: Disposition Engine
    Tasks:
    - AcceptanceCriteria:
      - Files written to quarantine are AES-256 encrypted and decryptable with the
        correct key
      - Quarantined objects are automatically expired after the configured TTL
      - Unit tests cover encrypt/store, retrieve/decrypt, and TTL expiry paths
      AgentType: backend-engineer
      Dependencies: []
      Description: Implement the quarantine store service that writes AES-256 encrypted
        objects with configurable TTL. Service must support storing, retrieving, and
        expiring quarantined files. Expose a clean interface for the DispositionEngine
        to invoke on quarantine decisions.
      EstimatedEffort: M
      Files:
      - fileguard/services/quarantine.py
      ID: task-fileguard-feat-disposition-1
      Title: Implement QuarantineService with AES-256 encryption and TTL
    - AcceptanceCriteria:
      - Block, quarantine, and pass-with-flags actions are correctly resolved from
        tenant and file-type rules
      - Quarantine action invokes QuarantineService and records the quarantine reference
      - Any unhandled exception results in a reject/block outcome with no file passing
        through
      - Unit tests cover all three disposition outcomes and the fail-secure exception
        path
      AgentType: backend-engineer
      Dependencies:
      - task-fileguard-feat-disposition-1
      Description: Implement the DispositionEngine that evaluates AV and PII findings
        against per-tenant, per-file-type disposition rules to produce a final action
        of block, quarantine, or pass-with-flags. On quarantine decisions, delegate
        to QuarantineService. Any unhandled exception must trigger the fail-secure
        path and reject the file.
      EstimatedEffort: M
      Files:
      - fileguard/core/disposition.py
      ID: task-fileguard-feat-disposition-2
      Title: Implement DispositionEngine rule evaluation with fail-secure default
  - FeatureID: fileguard-feat-pipeline-orchestrator
    FeatureTitle: Scan Pipeline Orchestrator
    Tasks:
    - AcceptanceCriteria:
      - ScanContext instantiates with required file metadata and optional step-result
        fields
      - All pipeline-step result fields are typed and documented with defaults
      - Unit tests confirm field assignment and serialisation round-trip
      AgentType: backend-engineer
      Dependencies: []
      Description: Define the ScanContext dataclass in fileguard/core/context.py as
        the shared state object passed across all pipeline steps. Include fields for
        file metadata, extracted content, AV results, PII findings, redaction output,
        disposition decision, and audit trail entries.
      EstimatedEffort: S
      Files:
      - fileguard/core/context.py
      ID: task-fileguard-feat-pipeline-orchestrator-1
      Title: Implement ScanContext shared dataclass
    - AcceptanceCriteria:
      - Pipeline executes all six steps in order and populates ScanContext correctly
      - Each step is wrapped in a named OTel span visible in trace output
      - Any step raising an exception halts the pipeline and marks context with a
        failed disposition
      - Integration test covers a happy-path run and a mid-pipeline failure scenario
      AgentType: backend-engineer
      Dependencies:
      - task-fileguard-feat-pipeline-orchestrator-1
      Description: 'Implement ScanPipeline in fileguard/core/pipeline.py that executes
        the ordered steps: extract → AV scan → PII detect → redact → disposition →
        audit. Each step mutates ScanContext in place. Wrap each step in an OpenTelemetry
        trace span and enforce fail-secure behaviour on any step failure.'
      EstimatedEffort: L
      Files:
      - fileguard/core/pipeline.py
      ID: task-fileguard-feat-pipeline-orchestrator-2
      Title: Implement ScanPipeline orchestration with OpenTelemetry spans
    - AcceptanceCriteria:
      - Celery task accepts a file reference and returns a structured disposition
        result
      - Batch submission fans out individual scan tasks and aggregates results
      - Transient failures trigger configured retries with exponential back-off
      - Worker integration test passes against a local Celery broker in eager mode
      AgentType: backend-engineer
      Dependencies:
      - task-fileguard-feat-pipeline-orchestrator-2
      Description: Wrap ScanPipeline in a Celery task in fileguard/workers/scan_worker.py
        to support single-file async invocation and batch fan-out. The worker should
        accept a file reference, instantiate ScanContext, run the pipeline, and return
        the disposition result. Configure retry policy and task routing.
      EstimatedEffort: M
      Files:
      - fileguard/workers/scan_worker.py
      ID: task-fileguard-feat-pipeline-orchestrator-3
      Title: Implement Celery scan worker for async and batch execution
  Sprint: 4
