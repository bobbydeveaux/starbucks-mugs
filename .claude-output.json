{
  "prTitle": "feat: implement Celery scan worker for async and batch execution",
  "prBody": "## Summary\n\n- Adds `fileguard/workers/scan_worker.py` with two Celery tasks:\n  - `scan_file_task`: wraps `ScanPipeline` for single-file async scanning; accepts base64-encoded file bytes, runs the full pipeline, returns a structured disposition result dict\n  - `scan_batch_task`: fans out a list of file references to individual `scan_file_task` subtasks via `celery.group`, aggregates results into a summary manifest\n- Retry policy: up to 3 retries with exponential back-off (2s→4s→8s) for transient errors; `PipelineError` (non-transient) returns `block` immediately without retrying\n- Pipeline built lazily per invocation; ClamAV included only when `CLAMAV_HOST` is set\n- Registered workers module in `celery_app.py`\n- Integration tests in `fileguard/tests/test_scan_worker.py` run in Celery eager mode (no broker required)\n- Documentation at `docs/concepts/fileguard/scan-worker.md` with cross-link from `pipeline.md`\n\nCloses #283",
  "testsPass": true,
  "filesChanged": [
    "fileguard/workers/__init__.py",
    "fileguard/workers/scan_worker.py",
    "fileguard/celery_app.py",
    "fileguard/tests/test_scan_worker.py"
  ],
  "docsUpdated": [
    "docs/concepts/fileguard/scan-worker.md",
    "docs/concepts/fileguard/pipeline.md"
  ],
  "docsReviewed": [
    "docs/concepts/fileguard/pipeline.md",
    "docs/concepts/fileguard/compliance-reports.md"
  ],
  "completedTasks": [1, 2, 3]
}
